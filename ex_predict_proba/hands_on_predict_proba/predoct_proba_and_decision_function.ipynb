{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# クラス分類器の不確実性推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# ジュピターノートブック上でグラフを表示させるための処理\n",
    "%matplotlib inline\n",
    "\n",
    "import mglearn\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_circles(noise=0.25, factor=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# わかりやすいようにクラスを\"blue\"と\"red\"にする\n",
    "y_named = np.array([\"blue\", \"red\"])[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_splitは任意の数の配列に適用できる。\n",
    "# すべての配列は整合するように分割される。\n",
    "X_train, X_test, y_train_named, t_test_named, y_train, y_test = train_test_split(X, y_named, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=0, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 勾配ブースティングモデルを構築\n",
    "gbrt = GradientBoostingClassifier(random_state=0)\n",
    "gbrt.fit(X_train, y_train_named)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 決定関数（Decision Function）\n",
    "\n",
    "2クラス分類の場合、decision_functionの結果の配列は(n_samples, )の形になり、サンプルごとに1つの浮動小数点が返される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.shape: (25, 2)\n",
      "Decision function shape: (25,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_test.shape: {}\".format(X_test.shape))\n",
    "print(\"Decision function shape: {}\".format(gbrt.decision_function(X_test).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⬆︎　この値には、あるデータポイントが「陽性」（この場合はクラス1）であると、モデルが信じている度合いがエンコードされている。正であれば陽性クラスを、負であれば「陰性」（つまり陽性以外）クラスを意味する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision function:\n",
      "[ 4.13592629 -1.7016989  -3.95106099 -3.62599351  4.28986668  3.66166106]\n"
     ]
    }
   ],
   "source": [
    "# decision_functionの最初のいくつかを表示\n",
    "print(\"Decision function:\\n{}\".format(gbrt.decision_function(X_test)[:6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⬆︎関数の符号だけ見れば、予測クラスがわかる。\n",
    "\n",
    "正であれば陽性クラスを、負であれば「陰性」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholded decision function:\n",
      "[ True False False False  True  True False  True  True  True False  True\n",
      "  True False  True False False False  True  True  True  True  True False\n",
      " False]\n",
      "Predictions:\n",
      "['red' 'blue' 'blue' 'blue' 'red' 'red' 'blue' 'red' 'red' 'red' 'blue'\n",
      " 'red' 'red' 'blue' 'red' 'blue' 'blue' 'blue' 'red' 'red' 'red' 'red'\n",
      " 'red' 'blue' 'blue']\n"
     ]
    }
   ],
   "source": [
    "print(\"Thresholded decision function:\\n{}\".format(gbrt.decision_function(X_test) > 0))\n",
    "print(\"Predictions:\\n{}\".format(gbrt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2クラス分類では、「陰性」クラスがclasses_属性の第1エントリに、「陽性」クラスが第2エントリになる。完全にpredictと同じ結果を再現したければ、classes_属性を使えばいい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred is equal to predictions: True\n"
     ]
    }
   ],
   "source": [
    "# True/Falseを0/1に\n",
    "greater_zero = (gbrt.decision_function(X_test) > 0).astype(int)\n",
    "\n",
    "# 0/1をclasses_のインデックスに使う\n",
    "pred = gbrt.classes_[greater_zero]\n",
    "\n",
    "# predはgbrt.predictの出力と同じになる\n",
    "print(\"pred is equal to predictions: {}\".format(np.all(pred == gbrt.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision function minimum: -7.69 maximum: 4.29\n"
     ]
    }
   ],
   "source": [
    "decision_function = gbrt.decision_function(X_test)\n",
    "print(\"Decision function minimum: {:.2f} maximum: {:.2f}\".format(np.min(decision_function), np.max(decision_function)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 確率の予測\n",
    "\n",
    "predict_probaの出力は、それぞれのクラスに属する確率で、decision_functionの出力よりも理解しやすい。\n",
    "\n",
    "出力配列の形は、2クラス分類問題では、常に(n_samples, 2)になる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of probabilitties: (25, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of probabilitties: {}\".format(gbrt.predict_proba(X_test).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⬆︎ gbrt.predict_proba()の戻り値の形\n",
    "\n",
    "各行の第1エントリ（第1列）は第1クラスの予測確率で、第2エントリ（第2列）は第2クラスの予測確率である。\n",
    "\n",
    "確率なので、predict_probaの出力は常に0から1であり、双方の和は常に1になっている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predited probabilities:\n",
      "[[0.01573626 0.98426374]\n",
      " [0.84575649 0.15424351]\n",
      " [0.98112869 0.01887131]\n",
      " [0.97406775 0.02593225]\n",
      " [0.01352142 0.98647858]\n",
      " [0.02504637 0.97495363]]\n"
     ]
    }
   ],
   "source": [
    "# predict_probaの出力(つまり確率)の最初の数行を見る\n",
    "print(\"Predited probabilities:\\n{}\".format(gbrt.predict_proba(X_test[:6])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⬆︎2つのクラスの確率の和なので、どちらかが50%以上の確率（確信度）になっており、そのクラスが`予測クラス`になる。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
